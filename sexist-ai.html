<!DOCTYPE HTML>
<html>
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="subpage">

		<!-- Header -->
			<header id="header">
				<a href="#menu">Menu</a>
			</header>

		<!-- Nav -->
		<nav id="menu" style="width: auto;">
			<ul class="links">
				<li><a href="index.html">Home</a></li>
				<li><a href="ai-strategy.html">AI-Strategie der EU und Gender Bias</a></li>
				<li><a href="sexist-ai.html">Sexistische und rassistische AI </a></li>
				<li><a href="gender-ai.html">Warum Sind Alex und Siri weiblich?</a></li>
				<li><a href="more.html">More...</a></li>
			</ul>
		</nav>

		<!-- Two -->
			<section id="two" class="wrapper style2">
				<div class="inner">
					<div class="box">
						<div class="content">
							<header class="align-center">
								<h2>Sexistische und rassistische AI </h2>
							</header>
							<p>Mehrfach hat man in Medien bereits davon gelesen, dass die AI in manchen Fällen sexistisch handelt. Doch woran liegt das? 
								Im Jahr 2016 hatte Microsoft versucht einen Chatbot auf dem Kurznachrichtendienst Twitter beizubringen wie junge Menschen sprechen, nach wenigen Stunden musste <a href="https://www.zeit.de/digital/internet/2016-03/microsoft-tay-chatbot-twitter-rassistisch"> das Projekt (2016) </a>  wieder abgebrochen werden, da der Chatbot von den Nutzer antrainiert wurde um diskriminierende Aussagen zu tätigen. </p>
							
							<p>Auch andere Plattformen wie Google und Bing haben teilweise <a href="https://www.inside-it.ch/de/post/deep-learning-macht-ai-systeme-besonders-sexistisch-20200619"> immer noch Probleme (2020)</a> mit ihren Algorithmus. 
								Bei Anfragen zu bestimmten Wörtern die im Englischen geschlechtsneutral sind, wurde bei manchen Berufsgruppen wie z.B nurse (übersetzt: Krankenpfleger/Krankenpflegerin) nur eine der beiden Geschlechter angezeigt.
							Wenn man mittlerweile versucht den Begriff “nurse” im Googler Übersetzer zu übersetzen so bekommt man folgende Antwort (Bild 1). </p>
							
							<div class="image auto" style="padding-left: 19%; padding-bottom: 3.4%;">
								<img src="images/sexist-ai.jpg" alt="" />
							</div>
							
							<p>Um <a href="diskriminierende Algorithmen (2019)"> diskriminierende Algorithmen (2019)</a> zu verhindern benötigt es eine Vielzahl an Menschen die diesen Algorithmus antrainieren. Wichtig ist , dass man Menschen mit verschiedener Herkunft, Alter, Geschlecht & Hobbys inkludiert. Nimmt man nur einen kleinen Teil der Gesellschaft zum Training kann es sein, dass vermehrt <a href="https://www.inside-it.ch/de/post/microsoft-will-gegen-diskriminierende-ki-vorgehen-20180528"> menschliche Vorurteile (2019)</a> in das Ergebnis einfließen.   </p>

							<p>Mittlerweile versuchen immer mehr Unternehmen wie z.B <a href="https://www.inside-it.ch/de/post/microsoft-will-gegen-diskriminierende-ki-vorgehen-20180528"> Facebook und Microsoft an Tools zu arbeiten die diskriminierende AI erkennen 2019</a> soll.
								<a href="https://www.technologyreview.com/2018/05/25/66849/microsoft-is-creating-an-oracle-for-catching-biased-ai-algorithms/"> “Of course, we can’t expect perfection—there’s always going to be some bias undetected or that can’t be eliminated—the goal is to do as well as we can,”</a> (Rich Caruna, 2018, Forscher bei Microsoft)
								Laut ihm wird es immer eine unbeobachtete oder eine nicht löschbare Voreingenommenheit geben, aber das Ziel ist es alles dagegen zu tun. </p>
					</div>
					</div>
				</div>
			</section>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>